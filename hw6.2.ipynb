{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArveloJuan/gitbrachmerge/blob/main/hw6.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import statement with all relevant packages.**"
      ],
      "metadata": {
        "id": "G6l9397wBqLy"
      },
      "id": "G6l9397wBqLy"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "df71db6e",
      "metadata": {
        "id": "df71db6e"
      },
      "outputs": [],
      "source": [
        "# Colab setup ------------------\n",
        "import os, sys, subprocess\n",
        "if \"google.colab\" in sys.modules:\n",
        "    cmd = \"pip install --upgrade iqplot colorcet datashader bebi103 watermark\"\n",
        "    process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    stdout, stderr = process.communicate()\n",
        "    data_path = \"https://s3.amazonaws.com/bebi103.caltech.edu/data/\"\n",
        "else:\n",
        "    data_path = \"../data/\"\n",
        "# ------------------------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import iqplot\n",
        "\n",
        "import math\n",
        "import bebi103 as be\n",
        "import warnings\n",
        "\n",
        "import tqdm\n",
        "\n",
        "import scipy.optimize\n",
        "import scipy.stats as st"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creates a data frame with the required data but also goes ahead and takes the average of the parents for the fortis set which does not have the proper column already and relabels the offspring column to match across both dataframes.**"
      ],
      "metadata": {
        "id": "OM7vVNRPBuil"
      },
      "id": "OM7vVNRPBuil"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "80e8c7bc",
      "metadata": {
        "scrolled": true,
        "id": "80e8c7bc"
      },
      "outputs": [],
      "source": [
        "fortis_df = pd.read_csv(os.path.join(data_path, \"fortis_beak_depth_heredity.csv\"), skiprows=3)\n",
        "scandens_df = pd.read_csv(os.path.join(data_path, \"scandens_beak_depth_heredity.csv\"), skiprows=3)\n",
        "\n",
        "#Data wrangling so that both dfs have a \"mid_parent\" and \"mid_offspring\" column\n",
        "fortis_df[\"mid_parent\"] = (fortis_df[\"Male BD\"] + fortis_df[\"Female BD\"])/2\n",
        "fortis_df.rename(columns = {\"Mid-offspr\": \"mid_offspring\"}, inplace = True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**These functions set up the definitions needed to run the mle function later on by properly unpacking parameters into a log likelihood function for the bivariate normal distribution. This code also goes ahead and ignores inapproriate sigma matrixes that would not work. The second definition uses optimize to find the MLEs. Here we assume that the input of variables will be mus followed by sigmas in reading order without inputting the repeat. The reason we have put this condition of the sigma matrix having to be positive is because a negative variance is meaningless in probability so we should avoid them.**"
      ],
      "metadata": {
        "id": "m_elYitPCrua"
      },
      "id": "m_elYitPCrua"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "d37ea39c",
      "metadata": {
        "id": "d37ea39c"
      },
      "outputs": [],
      "source": [
        "def log_likelihood(params, data):\n",
        "    \"\"\"\n",
        "    converts array of parameters into the inputs for multivariate normal distribution\n",
        "    \"\"\"\n",
        "    \n",
        "    mu = params[0:2]\n",
        "    sigma = [[params[2], params[3]],\n",
        "             [params[3], params[4]]]\n",
        "             \n",
        "    if(np.linalg.det(sigma) <= 0):\n",
        "        return -np.inf\n",
        "    return np.sum(scipy.stats.multivariate_normal.logpdf(data, mu, sigma))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "877b0964",
      "metadata": {
        "scrolled": true,
        "id": "877b0964"
      },
      "outputs": [],
      "source": [
        "def parametric_mle(data):\n",
        "    '''\n",
        "    Computes a parametric mle for the \"mid_parent\" and \"mid_offspring\" values of a dataframe\n",
        "    '''  \n",
        "    \n",
        "    #data = np.asarray(data)\n",
        "    #print(data[0])\n",
        "    #print(data)\n",
        "    d = data[:, 0]\n",
        "    ell = data[:, 1]\n",
        "    #d = df['mid_parent'].values\n",
        "    #ell = df['mid_offspring'].values\n",
        "    #arr = df[[\"mid_parent\", \"mid_offspring\"]].values,\n",
        "    res = scipy.optimize.minimize(\n",
        "        fun = lambda params, data: -log_likelihood(params, data), \n",
        "        x0 = np.array([1,1,1,0,1]), #the matrix must be positive definite\n",
        "        args = (data),\n",
        "        method = 'Powell'\n",
        "    )\n",
        "    return res.x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using the definition provided in the notes this function calculates the heredity value. This value is defined as $h^2 = \\frac{σ_{op}}{σ_p^2}$. Here we assume the organization of the parameter list again.**"
      ],
      "metadata": {
        "id": "04TfYAV5DhPq"
      },
      "id": "04TfYAV5DhPq"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "90aa0cff",
      "metadata": {
        "id": "90aa0cff"
      },
      "outputs": [],
      "source": [
        "def heredity(params):\n",
        "    '''\n",
        "    Converts 1d array of parameters into a measure of heretability\n",
        "    ''' \n",
        "    \n",
        "    return (params[3]/params[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here we use the definitions above and actually supply them a dataset to operate on.**"
      ],
      "metadata": {
        "id": "G7PhBjmFF0YU"
      },
      "id": "G7PhBjmFF0YU"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "762a8dbc",
      "metadata": {
        "id": "762a8dbc"
      },
      "outputs": [],
      "source": [
        "data = fortis_df[[\"mid_parent\", \"mid_offspring\"]].values\n",
        "\n",
        "fortis_mle = parametric_mle(data)\n",
        "#scandens_mle = parametric_mle(scandens_df)w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "363491ff",
      "metadata": {
        "id": "363491ff",
        "outputId": "d796b7bd-ff13-4775-ad26-c4dca5ac91f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.48427361, 9.3046489 , 0.4763311 , 0.34438081, 0.46927458])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "fortis_mle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Above in this array is our parametric likelihood estimates for the parameters of the matrix. The first two values are the means and the next four are the variances needed to construct the matrix in reading order omitting the repeated variance.**"
      ],
      "metadata": {
        "id": "X8VI5XRnGHWh"
      },
      "id": "X8VI5XRnGHWh"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "3ab78990",
      "metadata": {
        "id": "3ab78990",
        "outputId": "954dd599-cdac-46b4-918b-87cc7e02d465",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7229861914395019"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "heredity(fortis_mle)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is our calculated value for the heredity of beak depth across generations this is represented as the ratio of covariances between the parents and children versus the parents alone as described above.**"
      ],
      "metadata": {
        "id": "lOb0fR39GnwP"
      },
      "id": "lOb0fR39GnwP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code block here defines the generating function and bootstraping function together for simplicity to construct confidence intervals.**"
      ],
      "metadata": {
        "id": "B2EHl6vYHwKq"
      },
      "id": "B2EHl6vYHwKq"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "b1e7ee03",
      "metadata": {
        "id": "b1e7ee03"
      },
      "outputs": [],
      "source": [
        "def genfun(*params, size):\n",
        "    \"\"\"\n",
        "    This function generates the bivariate normal distribution based on the log\n",
        "    of parameters.\n",
        "    \"\"\"\n",
        "    mu = params[0:2]\n",
        "    sigma = [[params[2], params[3]],\n",
        "             [params[3], params[4]]]\n",
        "    return  scipy.stats.multivariate_normal.rvs(mu, sigma, size=size)\n",
        "\n",
        "def draw_parametric_bs_reps_mle(\n",
        "    mle_fun, gen_fun, data, args=(), size=1, progress_bar=False\n",
        "):\n",
        "    \"\"\"Draw parametric bootstrap replicates of maximum likelihood estimator.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mle_fun : function\n",
        "        Function with call signature mle_fun(data, *args) that computes\n",
        "        a MLE for the parameters\n",
        "    gen_fun : function\n",
        "        Function to randomly draw a new data set out of the model\n",
        "        distribution parametrized by the MLE. Must have call\n",
        "        signature `gen_fun(*params, size)`.\n",
        "    data : one-dimemsional Numpy array\n",
        "        Array of measurements\n",
        "    args : tuple, default ()\n",
        "        Arguments to be passed to `mle_fun()`.\n",
        "    size : int, default 1\n",
        "        Number of bootstrap replicates to draw.\n",
        "    progress_bar : bool, default False\n",
        "        Whether or not to display progress bar.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    output : numpy array\n",
        "        Bootstrap replicates of MLEs.\n",
        "    \"\"\"\n",
        "    params = mle_fun(data)\n",
        "\n",
        "    if progress_bar:\n",
        "        iterator = tqdm.tqdm(range(size))\n",
        "    else:\n",
        "        iterator = range(size)\n",
        "\n",
        "    return np.array(\n",
        "        [mle_fun(gen_fun(*params, size=len(data))) for _ in iterator]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This code implements the function above and constructs a confidence interval from the bootstrap samples. The first confidence is for heredity as stated. The second is for the two means and then the variances in reading form ignoring the repeat. The first array is the low bound for these terms in this order and the second the high bound.** "
      ],
      "metadata": {
        "id": "lUpRr8LdIDva"
      },
      "id": "lUpRr8LdIDva"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "3f44e79b",
      "metadata": {
        "id": "3f44e79b",
        "outputId": "1a23dd96-259e-4e25-eccf-8e6e953e4af3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "our confidence interval for the heredity h squared is: 0.7125032820678228 to 0.9728471431298831\n",
            "\n",
            "[[9.41776686 9.23745286 0.40822864 0.29086425 0.40320915]\n",
            " [9.55713477 9.36018782 0.54326249 0.39714407 0.52512951]]\n"
          ]
        }
      ],
      "source": [
        "bs_reps_parametric = draw_parametric_bs_reps_mle(\n",
        "    parametric_mle,\n",
        "    genfun,\n",
        "    data=fortis_df[[\"mid_parent\", \"mid_offspring\"]].values,\n",
        "    args=(),\n",
        "    size=100,\n",
        "    progress_bar=False,\n",
        ")\n",
        "\n",
        "CI = np.percentile(bs_reps_parametric, [2.5, 97.5], axis=0)\n",
        "low_bo = np.percentile(bs_reps_parametric, [2.5], axis=0)\n",
        "high_bo = np.percentile(bs_reps_parametric, [97.5], axis=0)\n",
        "low_hered = low_bo[0][3]/ low_bo[0][2]\n",
        "high_hered = high_bo[0][3]/low_bo[0][2]\n",
        "\n",
        "print('our confidence interval for the heredity h squared is: ' + str(low_hered)\n",
        "      + \" to \" +str(high_hered)+ '\\n')\n",
        "print(CI)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here we decided to a non-parametric hypothesis to try to understand if the distributions for the adult and offspring are actually the same which is our null hypothesis that the distributions are the same. To do so what we do is create a super data set from both of these distributions and then mix up the values. Then we pull properly sized distributions from this super data set. Then the value we decided could be informative as a test statistic was the difference in the mean values of the two data sets showing how the average beak depth had changed across the generation. For each of the newly created mixed distribution pairs we will take difference of the means. And we want to measure the amount of differences that are at least as extreme as what we observed between the two distributions in the field. The fraction of these values will be our p value.**"
      ],
      "metadata": {
        "id": "eygDirlJLa-j"
      },
      "id": "eygDirlJLa-j"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "71b4e7bf",
      "metadata": {
        "id": "71b4e7bf",
        "outputId": "98c42257-e2c7-4952-93e8-dde627e36dde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The p-value of Non-parametric Hypothesis test for the means of the parent and offspring generations being equal are:\n",
            "9e-05  for fortis and\n",
            "0.00139  for scandens.\n"
          ]
        }
      ],
      "source": [
        "# Non-parametric Hypothesis test \n",
        "\n",
        "def draw_perm_sample(x, y):\n",
        "    \"\"\"Generate a permutation sample.\"\"\"\n",
        "\n",
        "    concat_data = np.concatenate((x, y))\n",
        "    np.random.shuffle(concat_data)\n",
        "\n",
        "    return concat_data[:len(x)], concat_data[len(x):]\n",
        "\n",
        "\n",
        "def draw_perm_reps(x, y, stat_fun, size=1):\n",
        "    \"\"\"Generate array of permuation replicates.\"\"\"\n",
        "\n",
        "    return np.array([stat_fun(*draw_perm_sample(x, y)) for _ in range(size)])\n",
        "\n",
        "def draw_perm_reps_diff_mean(x, y, size=1):\n",
        "    \"\"\"Generate array of permuation replicates.\"\"\"\n",
        "    \n",
        "    out = np.empty(size)\n",
        "    for i in range(size):\n",
        "        x_perm, y_perm = draw_perm_sample(x, y)\n",
        "        out[i] = np.mean(x_perm) - np.mean(y_perm)\n",
        "\n",
        "    return out\n",
        "\n",
        "def nhst(df):\n",
        "    diff_mean = np.mean(df[\"mid_parent\"].values) - np.mean(df[\"mid_offspring\"])\n",
        "    perm_reps = draw_perm_reps_diff_mean(df[\"mid_parent\"].values,\n",
        "                                         df[\"mid_offspring\"], size=100000)\n",
        "\n",
        "    return np.sum(perm_reps >= diff_mean) / len(perm_reps)\n",
        "\n",
        "print(\"The p-value of Non-parametric Hypothesis test for the means of the parent and offspring generations being equal are:\")\n",
        "print(nhst(fortis_df), \" for fortis and\")\n",
        "print(nhst(scandens_df), \" for scandens.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Given that the p values obtained via this method are negiglibly small. We should reject the null hypothesis that the distributions are the same.** "
      ],
      "metadata": {
        "id": "4rJMJO3oPl7n"
      },
      "id": "4rJMJO3oPl7n"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attributions: The coding was done in part by Sophia and in part by Juan as were comments."
      ],
      "metadata": {
        "id": "lrJuAByAQ6Yy"
      },
      "id": "lrJuAByAQ6Yy"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "74e1fc9c",
      "metadata": {
        "id": "74e1fc9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f84c45-d413-485f-d6d1-a96ff7257841"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.8.16\n",
            "IPython version      : 7.9.0\n",
            "\n",
            "pandas    : 1.3.5\n",
            "bokeh     : 2.3.3\n",
            "jupyterlab: not installed\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%load_ext watermark\n",
        "%watermark -v -p pandas,bokeh,jupyterlab"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}